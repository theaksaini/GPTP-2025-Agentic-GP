import os
import pickle
import sys
import llm_agent
import inspect


def analyze_experiment_results(exps: dict, taskid, base_save_folder):
    # exps: dict, e.g. ["lexicase", "tournament", "random", "AGP1", "AGP2"]
    num_runs = 100
    performance = {}
    for exp in exps:
        num_sols = 0
        num_invalids = 0
        avg_fitness = 0
        num_finished_runs = 0
        save_folder = f"{base_save_folder}/{exp}/{taskid}"
        for r in range(num_runs):
            save_file = f"{save_folder}/{r}.pkl"
            # open the file and read the results
            if os.path.exists(save_file):
                num_finished_runs += 1
                with open(save_file, "rb") as f:
                    result = pickle.load(f)
                    if result["best_individual"] == None:
                        num_invalids += 1
                    else:
                        if result["best_fitness"] == 0:
                            num_sols += 1
                        else:
                            avg_fitness += result["best_fitness"]

        avg_fitness = avg_fitness / (num_runs - num_invalids) if (num_runs - num_invalids) > 0 else sys.maxsize
        performance[exp] = {
            "num_solutions": num_sols,
            "num_invalids": num_invalids,
            "avg_fitness": avg_fitness,
            "num_finished_runs": num_finished_runs
        }
    return performance

if __name__ == "__main__":
    experiments = ["lexicase", "tournament", "random", "AGP1", "AGP2"]
    base_save_folder = "experimental_results"
    for taskid in ["task1", "task2"]:
        print(f"Performance for task {taskid}:")
        performance = analyze_experiment_results(experiments, taskid, base_save_folder)
        print(performance)

    # Print the selection methods generated by the Agentic AI
    #saved_responses_folder = "experiment2_valid_responses"
    #for exp in ["AGP1", "AGP2"]:
    #    num_iters = 10 if exp == "AGP1" else 20
    #    for iter in range(num_iters):
    #        print(f"Running {exp} iteration {iter+1}/{num_iters}")
    #        code = llm_agent.extract_llm_response(exp, iter, saved_responses_folder)  # results["task1"] contain the results for first task, and so on.
    #        print(f"Generated code:\n{code}\n")